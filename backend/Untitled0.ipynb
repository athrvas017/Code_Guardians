{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4VB1hcnLA4Vd"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets torch torchvision pillow timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAwklHTSDlob",
        "outputId": "2836eb38-8147-4b04-e444-295fe36c7bf5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = \"/content/drive/MyDrive/ai_image_dataset\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW9w9AUCA-I3",
        "outputId": "5b8006e2-02a4-4e8e-deaf-408b8f257250"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Parveshiiii/AI-vs-Real\", split=\"train\", streaming=True)\n"
      ],
      "metadata": {
        "id": "D3eeDr-7BDlg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"val\", \"test\"]\n",
        "classes = [\"real\", \"ai_generated\"]\n",
        "\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        os.makedirs(f\"{BASE_DIR}/{split}/{cls}\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "C2q_I7DCBEHD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "# ==========================\n",
        "# Parameters\n",
        "# ==========================\n",
        "counts_per_class = {\"real\": 500, \"ai_generated\": 500}  # ~1000 images total\n",
        "split_ratio = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}\n",
        "image_size = (224, 224)\n",
        "saved_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Folder structure must already exist\n",
        "# splits = [\"train\", \"val\", \"test\"]\n",
        "# classes = [\"real\", \"ai_generated\"]\n",
        "# BASE_DIR = \"/content/ai_image_dataset\"  # or your Drive path\n",
        "\n",
        "# ==========================\n",
        "# Helper function to save images\n",
        "# ==========================\n",
        "def save_image(img, path):\n",
        "    img = img.convert(\"RGB\").resize(image_size)\n",
        "    img.save(path, format=\"JPEG\", quality=85)\n",
        "\n",
        "# ==========================\n",
        "# Sample and save images\n",
        "# ==========================\n",
        "for sample in dataset:\n",
        "    # FIXED: Use 'class' key instead of 'label'\n",
        "    img_class = sample.get(\"class\")  # 1 = real, 0 = AI-generated\n",
        "    if img_class is None:\n",
        "        continue  # skip if key missing\n",
        "\n",
        "    label = \"real\" if img_class == 1 else \"ai_generated\"\n",
        "\n",
        "    # Check if we already have enough images\n",
        "    total_saved = sum(saved_counts[split][label] for split in splits)\n",
        "    if total_saved >= counts_per_class[label]:\n",
        "        continue\n",
        "\n",
        "    # Decide which split the image goes to\n",
        "    r = random.random()\n",
        "    if r < split_ratio[\"train\"]:\n",
        "        split = \"train\"\n",
        "    elif r < split_ratio[\"train\"] + split_ratio[\"val\"]:\n",
        "        split = \"val\"\n",
        "    else:\n",
        "        split = \"test\"\n",
        "\n",
        "    # Skip if this split is already full for this class\n",
        "    if saved_counts[split][label] >= counts_per_class[label] * split_ratio[split]:\n",
        "        continue\n",
        "\n",
        "    # Save image\n",
        "    out_path = f\"{BASE_DIR}/{split}/{label}/{saved_counts[split][label]}.jpg\"\n",
        "    save_image(sample[\"image\"], out_path)\n",
        "    saved_counts[split][label] += 1\n",
        "\n",
        "    # Stop if both classes are done\n",
        "    if all(sum(saved_counts[s][c] for s in splits) >= counts_per_class[c] for c in classes):\n",
        "        break\n",
        "\n",
        "# ==========================\n",
        "# Verify counts\n",
        "# ==========================\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        path = f\"{BASE_DIR}/{split}/{cls}\"\n",
        "        print(f\"{split} / {cls}: {len(os.listdir(path))} images\")\n"
      ],
      "metadata": {
        "id": "zC692dWLBFqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AIImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, split, transform=None):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        for cls_idx, cls in enumerate(classes):\n",
        "            folder = os.path.join(root_dir, split, cls)\n",
        "            for img_name in os.listdir(folder):\n",
        "                self.images.append(os.path.join(folder, img_name))\n",
        "                self.labels.append(cls_idx)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "train_dataset = AIImageDataset(BASE_DIR, \"train\", transform=transform)\n",
        "val_dataset   = AIImageDataset(BASE_DIR, \"val\", transform=transform)\n",
        "test_dataset  = AIImageDataset(BASE_DIR, \"test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ZDQXa5p2BIzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=2)\n",
        "model = model.to(device)\n",
        "\n",
        "# Freeze backbone\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "aVOdbwkBBMZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    train_loss = running_loss / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "tt35K0bBD7a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_acc = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "deZcON1aD99u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}